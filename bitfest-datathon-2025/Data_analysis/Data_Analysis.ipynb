{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd077173",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4496c681",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "File \u001b[1;32msklearn\\utils\\murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Load the train and test datasets\n",
    "new_train_data = pd.read_csv(\"train.csv\")\n",
    "new_test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Check basic structure of the datasets\n",
    "print(\"Train Dataset Overview:\\n\")\n",
    "print(new_train_data.info())\n",
    "print(\"\\nTest Dataset Overview:\\n\")\n",
    "print(new_test_data.info())\n",
    "\n",
    "# Display summary statistics for numerical columns\n",
    "print(\"\\nTrain Dataset Numerical Summary:\\n\", new_train_data.describe())\n",
    "print(\"\\nTest Dataset Numerical Summary:\\n\", new_test_data.describe())\n",
    "\n",
    "# Display first few rows of the datasets\n",
    "print(\"\\nTrain Dataset Sample Rows:\\n\", new_train_data.head())\n",
    "print(\"\\nTest Dataset Sample Rows:\\n\", new_test_data.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a9dd6",
   "metadata": {},
   "source": [
    "## Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884db80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate missing value percentages\n",
    "train_missing = new_train_data.isnull().mean() * 100\n",
    "test_missing = new_test_data.isnull().mean() * 100\n",
    "\n",
    "print(\"Train Dataset Missing Values (%):\\n\", train_missing[train_missing > 0].sort_values(ascending=False))\n",
    "print(\"\\nTest Dataset Missing Values (%):\\n\", test_missing[test_missing > 0].sort_values(ascending=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c8db0",
   "metadata": {},
   "source": [
    "## Unique Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2dc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display unique values in each column\n",
    "for col in new_train_data.columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Unique Values: {new_train_data[col].nunique()}\")\n",
    "    print(\"-\" * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a11b5c",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizing the target variable distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(new_train_data['matched_score'], kde=True, color='blue')\n",
    "plt.title('Distribution of Matched Score')\n",
    "plt.xlabel('Matched Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Analyzing the impact of skills_required on matched_score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='skills_required', y='matched_score', data=new_train_data)\n",
    "plt.title('Skills Required vs Matched Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for numerical columns\n",
    "numerical_cols = new_train_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "corr_matrix = new_train_data[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7efae",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2287c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filling missing values with a placeholder or strategy\n",
    "new_train_data.fillna(\"Unknown\", inplace=True)\n",
    "new_test_data.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "print(\"Missing values handled successfully.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5431c",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = new_train_data.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    new_train_data[col] = label_encoder.fit_transform(new_train_data[col])\n",
    "    new_test_data[col] = label_encoder.transform(new_test_data[col])\n",
    "\n",
    "print(\"Categorical columns encoded successfully.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335aa03",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop columns not useful for modeling\n",
    "X = new_train_data.drop(columns=['matched_score', 'address'])\n",
    "y = new_train_data['matched_score']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and validation sets successfully.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6ce8f",
   "metadata": {},
   "source": [
    "## Feature Importance Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5585f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Plot feature importance\n",
    "importance = rf.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "features = X_train.columns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=importance[indices], y=features[indices], palette='viridis')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8deb46",
   "metadata": {},
   "source": [
    "## Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e497e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the processed data for reuse\n",
    "new_train_data.to_csv(\"cleaned_train_data.csv\", index=False)\n",
    "new_test_data.to_csv(\"cleaned_test_data.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned data saved successfully.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
