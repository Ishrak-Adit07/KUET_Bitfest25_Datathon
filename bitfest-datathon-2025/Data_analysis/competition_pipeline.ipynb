{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install lightgbm pandas scikit-learn joblib\n", "import re\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import train_test_split, KFold\n", "from sklearn.metrics import mean_squared_error\n", "import lightgbm as lgbm\n", "import joblib\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Feature Engineering"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FeatureEngineer:\n", "    def __init__(self):\n", "        self.label_encoders = {}\n", "        self.tfidf_vectorizers = {}\n", "    \n", "    def extract_year(self, date_str):\n", "        if pd.isna(date_str):\n", "            return None\n", "        try:\n", "            return int(re.findall(r'\\d{4}', str(date_str))[0])\n", "        except:\n", "            return None\n", "    \n", "    def process_dates(self, df):\n", "        df['experience_years'] = df.apply(\n", "            lambda x: self.extract_year(x['end_dates']) - self.extract_year(x['start_dates'])\n", "            if self.extract_year(x['end_dates']) and self.extract_year(x['start_dates'])\n", "            else 0, axis=1\n", "        )\n", "        return df\n", "    \n", "    def process_categorical(self, df, col):\n", "        if col not in self.label_encoders:\n", "            self.label_encoders[col] = LabelEncoder()\n", "            df[f'{col}_encoded'] = self.label_encoders[col].fit_transform(df[col].fillna('MISSING'))\n", "        else:\n", "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col].fillna('MISSING'))\n", "        return df\n", "    \n", "    def process_text(self, df, col):\n", "        if col not in self.tfidf_vectorizers:\n", "            self.tfidf_vectorizers[col] = TfidfVectorizer(max_features=100)\n", "            tfidf_features = self.tfidf_vectorizers[col].fit_transform(df[col].fillna(''))\n", "        else:\n", "            tfidf_features = self.tfidf_vectorizers[col].transform(df[col].fillna(''))\n", "        tfidf_df = pd.DataFrame(tfidf_features.toarray(), index=df.index, \n", "                                columns=[f'{col}_tfidf_{i}' for i in range(tfidf_features.shape[1])])\n", "        return tfidf_df\n", "    \n", "    def process_skills_match(self, df):\n", "        df['skills_required'] = df['skills_required'].fillna('')\n", "        df['skills'] = df['skills'].fillna('')\n", "        required_skills = df['skills_required'].apply(lambda x: set(x.split(',')))\n", "        candidate_skills = df['skills'].apply(lambda x: set(x.split(',')))\n", "        df['skills_match_ratio'] = [\n", "            len(req.intersection(cand)) / len(req) if len(req) > 0 else 0\n", "            for req, cand in zip(required_skills, candidate_skills)\n", "        ]\n", "        return df\n", "\n", "    def transform(self, df):\n", "        df = self.process_dates(df)\n", "        for col in ['degree_names', 'result_types', 'major_field_of_studies']:\n", "            df = self.process_categorical(df, col)\n", "        text_features = ['skills', 'career_objective', 'responsibilities']\n", "        tfidf_dfs = [self.process_text(df, col) for col in text_features]\n", "        tfidf_combined = pd.concat(tfidf_dfs, axis=1)\n", "        df = self.process_skills_match(df)\n", "        df = pd.concat([df, tfidf_combined], axis=1)\n", "        return df\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Training and Cross-Validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_df = pd.read_csv('/kaggle/input/bitfest-datathon-2025/train.csv')\n", "fe = FeatureEngineer()\n", "train_df = fe.transform(train_df)\n", "\n", "tfidf_cols = [col for col in train_df.columns if '_tfidf_' in col]\n", "cat_cols = [col for col in train_df.columns if 'encoded' in col]\n", "num_cols = ['experience_years', 'skills_match_ratio']\n", "feature_cols = tfidf_cols + cat_cols + num_cols\n", "\n", "X = train_df[feature_cols]\n", "y = train_df['matched_score']\n", "\n", "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n", "cv_scores = []\n", "\n", "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n", "    print(f\"Training Fold {fold + 1}\")\n", "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n", "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n", "    train_data = lgbm.Dataset(X_train, label=y_train)\n", "    val_data = lgbm.Dataset(X_val, label=y_val)\n", "\n", "    params = {\n", "        'objective': 'regression_l2',\n", "        'metric': 'l2',\n", "        'num_leaves': 31,\n", "        'learning_rate': 0.05,\n", "        'feature_fraction': 0.9,\n", "        'max_depth': 8,\n", "        'reg_alpha': 0.1,\n", "        'reg_lambda': 0.1\n", "    }\n", "\n", "    model = lgbm.train(\n", "        params,\n", "        train_data,\n", "        num_boost_round=1000,\n", "        valid_sets=[train_data, val_data],\n", "        callbacks=[lgbm.early_stopping(stopping_rounds=50), lgbm.log_evaluation(100)]\n", "    )\n", "\n", "    val_preds = model.predict(X_val)\n", "    fold_score = mean_squared_error(y_val, val_preds)\n", "    cv_scores.append(fold_score)\n", "\n", "print(f\"CV MSE: {np.mean(cv_scores):.6f} \u00b1 {np.std(cv_scores):.6f}\")\n", "model.save_model('trained_lgbm_model.txt')\n", "joblib.dump(fe, 'trained_feature_engineer.pkl')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Inference"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fe = joblib.load('trained_feature_engineer.pkl')\n", "model = lgbm.Booster(model_file='trained_lgbm_model.txt')\n", "test_df = pd.read_csv('/kaggle/input/bitfest-datathon-2025/test.csv')\n", "test_df = fe.transform(test_df)\n", "\n", "predictions = model.predict(test_df[feature_cols])\n", "submission = pd.DataFrame({'ID': test_df['ID'], 'matched_score': predictions})\n", "submission.to_csv('submission.csv', index=False)\n", "print(\"Predictions saved to submission.csv\")\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 4}